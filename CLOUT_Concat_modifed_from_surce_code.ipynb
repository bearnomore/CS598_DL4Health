{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29591fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9170e7f",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1829b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, epochs=5, batchsize=50, vocabsize=5, embsize=100):\n",
    "        super(RNN, self).__init__()\n",
    "        self.epochs = 5\n",
    "        self.batchsize = batchsize\n",
    "        self.vocabsize = vocabsize\n",
    "        self.embsize = embsize\n",
    "\n",
    "        self.emb_icd = nn.Linear(vocabsize_icd, embsize_icd)\n",
    "        self.emb_meds = nn.Linear(vocabsize_meds, embsize_meds)\n",
    "        self.emb_labs = nn.Linear(vocabsize_labs, embsize_labs)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embsize, hidden_size=embsize, num_layers=1)\n",
    "        self.out = nn.Linear(embsize, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_icd, input_med, input_lab, hidden=None, force=True, steps=0):\n",
    "        if force or steps == 0: steps = len(input_icd)\n",
    "        outputs = Variable(torch.zeros(steps, 1, 1))\n",
    "\n",
    "        input_icd = F.relu(self.emb_icd(input_icd))\n",
    "        input_med = F.relu(self.emb_meds(input_med))\n",
    "        input_lab = F.relu(self.emb_labs(input_lab))\n",
    "\n",
    "        inputs = torch.cat((input_icd, input_med, input_lab),1)\n",
    "\n",
    "        inputs = inputs.view(inputs.size()[0],1,inputs.size()[1])\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.out(outputs)\n",
    "        return outputs.squeeze(), hidden\n",
    "\n",
    "    def predict(self, input_icd, input_med, input_lab):\n",
    "        out, hid = self.forward(input_icd, input_med, input_lab, None)\n",
    "        return self.sig(out[-1]).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc3a80",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a86bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/MIMIC_Processed/'\n",
    "\n",
    "n_epochs = 5\n",
    "vocabsize_icd = 942\n",
    "vocabsize_meds = 3202\n",
    "vocabsize_labs = 284 #all 681\n",
    "vocabsize = vocabsize_icd+vocabsize_meds+vocabsize_labs\n",
    "\n",
    "embsize_icd = 50\n",
    "embsize_meds = 75\n",
    "embsize_labs = 50\n",
    "embsize = embsize_icd + embsize_labs + embsize_meds\n",
    "\n",
    "input_seqs_icd = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.3digitICD9.seqs', 'rb'))\n",
    "input_seqs_meds = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.meds.seqs', 'rb'))\n",
    "input_seqs_labs = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.abnlabs.seqs', 'rb'))\n",
    "input_seqs_fullicd = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.seqs', 'rb'))\n",
    "\n",
    "labels = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.morts', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea85aa6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8af7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared..\n"
     ]
    }
   ],
   "source": [
    "trainratio = 0.7\n",
    "validratio = 0.1\n",
    "testratio = 0.2\n",
    "\n",
    "trainlindex = int(len(input_seqs_icd)*trainratio)\n",
    "validlindex = int(len(input_seqs_icd)*(trainratio + validratio))\n",
    "\n",
    "print('Data prepared..')\n",
    "\n",
    "def convert_to_one_hot(code_seqs, len):\n",
    "    new_code_seqs = []\n",
    "    for code_seq in code_seqs:\n",
    "        one_hot_vec = np.zeros(len)\n",
    "        for code in code_seq:\n",
    "            one_hot_vec[code] = 1\n",
    "        new_code_seqs.append(one_hot_vec)\n",
    "    return np.array(new_code_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc2968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n",
      "Run 0\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.8531713486375656\n",
      "Test AUC_ROC:  0.8594790306599623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       923\n",
      "           1       0.70      0.73      0.72       585\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.76      0.77      0.77      1508\n",
      "weighted avg       0.78      0.78      0.78      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8377265933392096\n",
      "Test AUC_ROC:  0.8518691372429184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       923\n",
      "           1       0.69      0.73      0.71       585\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.76      0.76      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8140114206875407\n",
      "Test AUC_ROC:  0.817923715865211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81       923\n",
      "           1       0.87      0.35      0.49       585\n",
      "\n",
      "    accuracy                           0.73      1508\n",
      "   macro avg       0.78      0.66      0.65      1508\n",
      "weighted avg       0.76      0.73      0.69      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.7961598896255699\n",
      "Test AUC_ROC:  0.8086525728995937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       923\n",
      "           1       0.76      0.48      0.59       585\n",
      "\n",
      "    accuracy                           0.74      1508\n",
      "   macro avg       0.75      0.69      0.70      1508\n",
      "weighted avg       0.74      0.74      0.72      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.812846357260568\n",
      "Test AUC_ROC:  0.8278449130020095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       923\n",
      "           1       0.74      0.62      0.68       585\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.74      0.75      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Run 1\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.838282272846295\n",
      "Test AUC_ROC:  0.8501443814320744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       955\n",
      "           1       0.75      0.65      0.70       553\n",
      "\n",
      "    accuracy                           0.79      1508\n",
      "   macro avg       0.78      0.76      0.77      1508\n",
      "weighted avg       0.79      0.79      0.79      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8390902629708601\n",
      "Test AUC_ROC:  0.8475104854056408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       955\n",
      "           1       0.69      0.72      0.70       553\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.76      0.77      0.76      1508\n",
      "weighted avg       0.78      0.78      0.78      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8307934014139827\n",
      "Test AUC_ROC:  0.843833256014315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       955\n",
      "           1       0.65      0.76      0.70       553\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.75      0.76      0.75      1508\n",
      "weighted avg       0.77      0.76      0.77      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8336737365802567\n",
      "Test AUC_ROC:  0.8396409872849664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       955\n",
      "           1       0.70      0.66      0.68       553\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.75      0.75      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8040923203531215\n",
      "Test AUC_ROC:  0.8210901034812492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       955\n",
      "           1       0.70      0.61      0.65       553\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.75      0.73      0.74      1508\n",
      "weighted avg       0.76      0.76      0.76      1508\n",
      "\n",
      "Run 2\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.867043888925727\n",
      "Test AUC_ROC:  0.860588031043835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       943\n",
      "           1       0.74      0.71      0.72       565\n",
      "\n",
      "    accuracy                           0.80      1508\n",
      "   macro avg       0.78      0.78      0.78      1508\n",
      "weighted avg       0.80      0.80      0.80      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8504593712471175\n",
      "Test AUC_ROC:  0.8483450482831107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       943\n",
      "           1       0.72      0.68      0.70       565\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.76      0.76      0.76      1508\n",
      "weighted avg       0.78      0.78      0.78      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8238475196899705\n",
      "Test AUC_ROC:  0.8314867819705515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       943\n",
      "           1       0.77      0.61      0.68       565\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.78      0.75      0.76      1508\n",
      "weighted avg       0.78      0.78      0.78      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.83041207111229\n",
      "Test AUC_ROC:  0.8290899877063411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       943\n",
      "           1       0.79      0.51      0.62       565\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.77      0.71      0.73      1508\n",
      "weighted avg       0.77      0.77      0.75      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.83033102726757\n",
      "Test AUC_ROC:  0.83631790838878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       943\n",
      "           1       0.70      0.69      0.70       565\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.76      0.76      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Run 3\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.8598331239231678\n",
      "Test AUC_ROC:  0.8585857437390092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       956\n",
      "           1       0.69      0.71      0.70       552\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.76      0.76      0.76      1508\n",
      "weighted avg       0.78      0.78      0.78      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8606306380865678\n",
      "Test AUC_ROC:  0.8520101873749318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       956\n",
      "           1       0.74      0.63      0.68       552\n",
      "\n",
      "    accuracy                           0.79      1508\n",
      "   macro avg       0.77      0.75      0.76      1508\n",
      "weighted avg       0.78      0.79      0.78      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8380670062371626\n",
      "Test AUC_ROC:  0.834155751622097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       956\n",
      "           1       0.65      0.71      0.68       552\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.74      0.74      0.74      1508\n",
      "weighted avg       0.76      0.75      0.76      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8297532972696426\n",
      "Test AUC_ROC:  0.8266270238311807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79       956\n",
      "           1       0.63      0.77      0.69       552\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.74      0.76      0.74      1508\n",
      "weighted avg       0.77      0.75      0.76      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8409335429942895\n",
      "Test AUC_ROC:  0.81807880055788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75       956\n",
      "           1       0.58      0.80      0.68       552\n",
      "\n",
      "    accuracy                           0.72      1508\n",
      "   macro avg       0.72      0.74      0.71      1508\n",
      "weighted avg       0.76      0.72      0.72      1508\n",
      "\n",
      "Run 4\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC_ROC:  0.8550256178420735\n",
      "Test AUC_ROC:  0.863828218458691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       946\n",
      "           1       0.84      0.49      0.62       562\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.80      0.72      0.73      1508\n",
      "weighted avg       0.79      0.78      0.76      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8493595539481615\n",
      "Test AUC_ROC:  0.852138240804135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       946\n",
      "           1       0.81      0.56      0.66       562\n",
      "\n",
      "    accuracy                           0.79      1508\n",
      "   macro avg       0.80      0.74      0.75      1508\n",
      "weighted avg       0.79      0.79      0.78      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.827448764315853\n",
      "Test AUC_ROC:  0.8322116722969161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       946\n",
      "           1       0.77      0.57      0.65       562\n",
      "\n",
      "    accuracy                           0.78      1508\n",
      "   macro avg       0.78      0.73      0.74      1508\n",
      "weighted avg       0.78      0.78      0.77      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8223327305605785\n",
      "Test AUC_ROC:  0.8289727114729184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83       946\n",
      "           1       0.82      0.48      0.61       562\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.79      0.71      0.72      1508\n",
      "weighted avg       0.78      0.77      0.75      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8212816455696202\n",
      "Test AUC_ROC:  0.818542956670905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       946\n",
      "           1       0.66      0.70      0.68       562\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.74      0.74      0.74      1508\n",
      "weighted avg       0.76      0.76      0.76      1508\n",
      "\n",
      "Run 5\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.8458926462930775\n",
      "Test AUC_ROC:  0.8544254658385093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81       920\n",
      "           1       0.69      0.76      0.72       588\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.77      0.76      1508\n",
      "weighted avg       0.78      0.77      0.77      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8378766877149749\n",
      "Test AUC_ROC:  0.8505582667849749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78       920\n",
      "           1       0.65      0.82      0.73       588\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.76      0.77      0.76      1508\n",
      "weighted avg       0.78      0.76      0.76      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8255410588692584\n",
      "Test AUC_ROC:  0.8479277580597456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       920\n",
      "           1       0.69      0.74      0.71       588\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.76      0.76      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8140268274258725\n",
      "Test AUC_ROC:  0.835224415853298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       920\n",
      "           1       0.73      0.66      0.69       588\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.75      0.75      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8127433939847308\n",
      "Test AUC_ROC:  0.8320337917775806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78       920\n",
      "           1       0.64      0.81      0.72       588\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.75      0.76      0.75      1508\n",
      "weighted avg       0.77      0.75      0.75      1508\n",
      "\n",
      "Run 6\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.8657528620565738\n",
      "Test AUC_ROC:  0.8600767329753478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85       964\n",
      "           1       0.74      0.67      0.70       544\n",
      "\n",
      "    accuracy                           0.80      1508\n",
      "   macro avg       0.78      0.77      0.77      1508\n",
      "weighted avg       0.79      0.80      0.79      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8510483817737783\n",
      "Test AUC_ROC:  0.8497566817183304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       964\n",
      "           1       0.77      0.63      0.69       544\n",
      "\n",
      "    accuracy                           0.80      1508\n",
      "   macro avg       0.79      0.76      0.77      1508\n",
      "weighted avg       0.80      0.80      0.79      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8384780679559672\n",
      "Test AUC_ROC:  0.8365400750549181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       964\n",
      "           1       0.75      0.62      0.68       544\n",
      "\n",
      "    accuracy                           0.79      1508\n",
      "   macro avg       0.78      0.75      0.76      1508\n",
      "weighted avg       0.79      0.79      0.79      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8384560662398334\n",
      "Test AUC_ROC:  0.8313533530632171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81       964\n",
      "           1       0.66      0.72      0.69       544\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.76      0.75      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8332563273268649\n",
      "Test AUC_ROC:  0.8159400170856725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       964\n",
      "           1       0.70      0.62      0.66       544\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.73      0.74      1508\n",
      "weighted avg       0.76      0.77      0.76      1508\n",
      "\n",
      "Run 7\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.8638365059597937\n",
      "Test AUC_ROC:  0.8599910138371677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       962\n",
      "           1       0.76      0.64      0.70       546\n",
      "\n",
      "    accuracy                           0.80      1508\n",
      "   macro avg       0.78      0.76      0.77      1508\n",
      "weighted avg       0.79      0.80      0.79      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8572243966079583\n",
      "Test AUC_ROC:  0.8484594061517139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       962\n",
      "           1       0.79      0.56      0.65       546\n",
      "\n",
      "    accuracy                           0.79      1508\n",
      "   macro avg       0.79      0.74      0.75      1508\n",
      "weighted avg       0.79      0.79      0.78      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8403679653679652\n",
      "Test AUC_ROC:  0.8190754152292614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       962\n",
      "           1       0.72      0.57      0.64       546\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.72      0.73      1508\n",
      "weighted avg       0.76      0.77      0.76      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8268620648757636\n",
      "Test AUC_ROC:  0.8099655022731946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       962\n",
      "           1       0.72      0.59      0.65       546\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.73      0.74      1508\n",
      "weighted avg       0.76      0.77      0.76      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8342154420921545\n",
      "Test AUC_ROC:  0.8316331970178125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       962\n",
      "           1       0.68      0.67      0.67       546\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.74      0.74      1508\n",
      "weighted avg       0.76      0.77      0.76      1508\n",
      "\n",
      "Run 8\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC_ROC:  0.8591376609222806\n",
      "Test AUC_ROC:  0.8546267573830448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       922\n",
      "           1       0.67      0.77      0.72       586\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.76      0.77      0.76      1508\n",
      "weighted avg       0.78      0.77      0.77      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.8548691051926526\n",
      "Test AUC_ROC:  0.842166828307656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       922\n",
      "           1       0.70      0.69      0.69       586\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.75      0.75      0.75      1508\n",
      "weighted avg       0.76      0.76      0.76      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.833889607883205\n",
      "Test AUC_ROC:  0.8229050217289908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       922\n",
      "           1       0.68      0.69      0.68       586\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.74      0.74      0.74      1508\n",
      "weighted avg       0.75      0.75      0.75      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8322851153039832\n",
      "Test AUC_ROC:  0.8079205318605495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       922\n",
      "           1       0.63      0.71      0.67       586\n",
      "\n",
      "    accuracy                           0.73      1508\n",
      "   macro avg       0.72      0.72      0.72      1508\n",
      "weighted avg       0.74      0.73      0.73      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8291442453965443\n",
      "Test AUC_ROC:  0.806077084243335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.80       922\n",
      "           1       0.72      0.53      0.61       586\n",
      "\n",
      "    accuracy                           0.74      1508\n",
      "   macro avg       0.73      0.70      0.71      1508\n",
      "weighted avg       0.73      0.74      0.73      1508\n",
      "\n",
      "Run 9\n",
      "Epoch 1\n",
      "Validation AUC_ROC:  0.84805001173096\n",
      "Test AUC_ROC:  0.8389612089926308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.80       938\n",
      "           1       0.65      0.76      0.70       570\n",
      "\n",
      "    accuracy                           0.76      1508\n",
      "   macro avg       0.75      0.76      0.75      1508\n",
      "weighted avg       0.77      0.76      0.76      1508\n",
      "\n",
      "Epoch 2\n",
      "Validation AUC_ROC:  0.837325643878331\n",
      "Test AUC_ROC:  0.8310851756256312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       938\n",
      "           1       0.69      0.71      0.70       570\n",
      "\n",
      "    accuracy                           0.77      1508\n",
      "   macro avg       0.75      0.76      0.76      1508\n",
      "weighted avg       0.77      0.77      0.77      1508\n",
      "\n",
      "Epoch 3\n",
      "Validation AUC_ROC:  0.8277365302091139\n",
      "Test AUC_ROC:  0.8107601092282947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.78       938\n",
      "           1       0.64      0.72      0.68       570\n",
      "\n",
      "    accuracy                           0.74      1508\n",
      "   macro avg       0.73      0.74      0.73      1508\n",
      "weighted avg       0.75      0.74      0.74      1508\n",
      "\n",
      "Epoch 4\n",
      "Validation AUC_ROC:  0.8148249059631117\n",
      "Test AUC_ROC:  0.7872928590132047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       938\n",
      "           1       0.76      0.49      0.60       570\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.75      0.70      0.71      1508\n",
      "weighted avg       0.75      0.75      0.73      1508\n",
      "\n",
      "Epoch 5\n",
      "Validation AUC_ROC:  0.8119110868923552\n",
      "Test AUC_ROC:  0.7977406202072345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       938\n",
      "           1       0.69      0.59      0.64       570\n",
      "\n",
      "    accuracy                           0.75      1508\n",
      "   macro avg       0.73      0.71      0.72      1508\n",
      "weighted avg       0.74      0.75      0.74      1508\n",
      "\n",
      "Average AUCROC: 0.8560706584360271 +/- 0.00680141452996701\n",
      "The training is complete!\n",
      "The time used is:  5889.640625\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "print('Starting training..')\n",
    "\n",
    "batchsize = 50\n",
    "\n",
    "best_aucrocs = []\n",
    "for run in range(10):\n",
    "    print('Run', run)\n",
    "\n",
    "    perm = np.random.permutation(len(input_seqs_icd))\n",
    "    rinput_seqs_icd = [input_seqs_icd[i] for i in perm]\n",
    "    rinput_seqs_meds = [input_seqs_meds[i] for i in perm]\n",
    "    rinput_seqs_labs = [input_seqs_labs[i] for i in perm]\n",
    "    rinput_seqs_fullicd = [input_seqs_fullicd[i] for i in perm]\n",
    "    rlabels = [labels[i] for i in perm]\n",
    "    rlabels = torch.tensor(rlabels)\n",
    "\n",
    "    train_input_seqs_icd = rinput_seqs_icd[:trainlindex]\n",
    "    train_input_seqs_meds = rinput_seqs_meds[:trainlindex]\n",
    "    train_input_seqs_labs = rinput_seqs_labs[:trainlindex]\n",
    "    train_labels = rlabels[:trainlindex]\n",
    "    train_labels = train_labels.reshape(train_labels.shape[0],1)\n",
    "\n",
    "    valid_input_seqs_icd = rinput_seqs_icd[trainlindex:validlindex]\n",
    "    valid_input_seqs_meds = rinput_seqs_meds[trainlindex:validlindex]\n",
    "    valid_input_seqs_labs = rinput_seqs_labs[trainlindex:validlindex]\n",
    "    valid_labels = rlabels[trainlindex:validlindex]\n",
    "\n",
    "    test_input_seqs_icd = rinput_seqs_icd[validlindex:]\n",
    "    test_input_seqs_meds = rinput_seqs_meds[validlindex:]\n",
    "    test_input_seqs_labs = rinput_seqs_labs[validlindex:]\n",
    "    test_input_seqs_fullicd = rinput_seqs_fullicd[validlindex:]\n",
    "\n",
    "    test_labels = rlabels[validlindex:]\n",
    "\n",
    "    n_iters = len(train_input_seqs_icd)\n",
    "\n",
    "    model = RNN(n_epochs, 1, vocabsize, embsize)\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    aucrocs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        print('Epoch', (epoch+1))\n",
    "\n",
    "        for i in (range(0, n_iters, batchsize)):\n",
    "            batch_icd = train_input_seqs_icd[i:i+batchsize]\n",
    "            batch_meds = train_input_seqs_meds[i:i+batchsize]\n",
    "            batch_labs = train_input_seqs_labs[i:i+batchsize]\n",
    "\n",
    "            batch_train_labels = train_labels[i:i+batchsize]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses = []\n",
    "\n",
    "            for j in range(len(batch_icd)):\n",
    "                icd_onehot = convert_to_one_hot(batch_icd[j], vocabsize_icd)\n",
    "                med_onehot = convert_to_one_hot(batch_meds[j], vocabsize_meds)\n",
    "                lab_onehot = convert_to_one_hot(batch_labs[j], vocabsize_labs)\n",
    "\n",
    "                icd_inputs = Variable(torch.from_numpy(icd_onehot).float())\n",
    "                med_inputs = Variable(torch.from_numpy(med_onehot).float())\n",
    "                lab_inputs = Variable(torch.from_numpy(lab_onehot).float())\n",
    "\n",
    "                targets = Variable(batch_train_labels[j].float())\n",
    "                \n",
    "                # Use teacher forcing 50% of the time\n",
    "                force = random.random() < 0.5\n",
    "                outputs, hidden = model(icd_inputs, med_inputs, lab_inputs, None, force)\n",
    "\n",
    "                #print outputs[-1], targets\n",
    "                loss = criterion(outputs[-1].view(1), targets)\n",
    "                losses.append(loss)\n",
    "#                 losses.append(criterion(outputs[-1], targets))\n",
    "\n",
    "            loss = sum(losses)/len(batch_icd)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.data\n",
    "\n",
    "        #print(epoch, epoch_loss)\n",
    "\n",
    "        ## Validation phase\n",
    "        vpredictions = np.zeros(len(valid_input_seqs_icd))\n",
    "        for i in range(len(valid_input_seqs_icd)):\n",
    "            test_input_icd = Variable(torch.from_numpy(convert_to_one_hot(valid_input_seqs_icd[i], vocabsize_icd)).float())\n",
    "            test_input_med = Variable(torch.from_numpy(convert_to_one_hot(valid_input_seqs_meds[i], vocabsize_meds)).float())\n",
    "            test_input_lab = Variable(torch.from_numpy(convert_to_one_hot(valid_input_seqs_labs[i], vocabsize_labs)).float())\n",
    "            vpredictions[i] = model.predict(test_input_icd, test_input_med, test_input_lab)\n",
    "\n",
    "        print(\"Validation AUC_ROC: \", roc_auc_score(valid_labels, vpredictions))\n",
    "\n",
    "        ## Testing phase\n",
    "        predictions = np.zeros(len(test_input_seqs_icd))\n",
    "\n",
    "        # ICD_wise_corr = np.zeros(5)\n",
    "        # meds_wise_corr = np.zeros(5)\n",
    "        # labs_wise_corr = np.zeros(5)\n",
    "        # ICD_wise_tot = np.zeros(5)\n",
    "        # meds_wise_tot = np.zeros(5)\n",
    "        # labs_wise_tot = np.zeros(5)\n",
    "\n",
    "        for i in range(len(test_input_seqs_icd)):\n",
    "            test_input_icd = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_icd[i], vocabsize_icd)).float())\n",
    "            test_input_med = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_meds[i], vocabsize_meds)).float())\n",
    "            test_input_lab = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_labs[i], vocabsize_labs)).float())\n",
    "            predictions[i] = model.predict(test_input_icd, test_input_med, test_input_lab)\n",
    "\n",
    "            # ICD_wise_corr[get_avg(test_input_seqs_icd[i], 'i')] += int((predictions[i]>0.5)*1 == test_labels[i])\n",
    "            # ICD_wise_tot[get_avg(test_input_seqs_icd[i], 'i')] += 1\n",
    "\n",
    "            # meds_wise_corr[get_avg(test_input_seqs_meds[i], 'm')] += int((predictions[i]>0.5)*1 == test_labels[i])\n",
    "            # meds_wise_tot[get_avg(test_input_seqs_meds[i], 'm')] += 1\n",
    "\n",
    "            # labs_wise_corr[get_avg(test_input_seqs_labs[i], 'l')] += int((predictions[i]>0.5)*1 == test_labels[i])\n",
    "            # labs_wise_tot[get_avg(test_input_seqs_labs[i], 'l')] += 1\n",
    "\n",
    "        print(\"Test AUC_ROC: \", roc_auc_score(test_labels, predictions))\n",
    "\n",
    "        aucrocs.append(roc_auc_score(test_labels, predictions))\n",
    "        actual_predictions = (predictions>0.5)*1\n",
    "        print(classification_report(test_labels, actual_predictions))\n",
    "\n",
    "    best_aucrocs.append(max(aucrocs))\n",
    "\n",
    "print(\"Average AUCROC:\", np.mean(best_aucrocs), \"+/-\", np.std(best_aucrocs))\n",
    "\n",
    "end = time.process_time()\n",
    "print('The training is complete!')\n",
    "print('The time used is: ', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b302c",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da634f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_PATH = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/MIMIC data/'\n",
    "out_path = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/Output/'\n",
    "\n",
    "\n",
    "icditems = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.types', 'rb'))\n",
    "meditems = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.meds.types', 'rb'))\n",
    "labitems = pickle.load(open(DATA_PATH + 'MIMICIIIPROCESSED.abnlabs.types', 'rb'))\n",
    "\n",
    "model_name = 'CAE'\n",
    "\n",
    "interpretation_file = open(out_path + \"RNN_CLatent_Interpretations_\" + model_name + \".txt\", 'w')\n",
    "\n",
    "# overall_risk_factor_file = open(\"risk_factors_averaged.txt\", \"w\")\n",
    "\n",
    "\n",
    "labnames = {}\n",
    "lab_dict_file = open(MIMIC_PATH + 'D_LABITEMS.csv', 'r')\n",
    "lab_dict_file.readline()\n",
    "for line in lab_dict_file:\n",
    "    tokens = line.strip().split(',')\n",
    "    labnames[tokens[1].replace('\"','')] = tokens[2]\n",
    "lab_dict_file.close()\n",
    "\n",
    "icdnames = {}\n",
    "icd_dict_file = open(MIMIC_PATH + 'D_ICD_DIAGNOSES.csv', 'r')\n",
    "icd_dict_file.readline()\n",
    "for line in icd_dict_file:\n",
    "    tokens = line.strip().split(',')\n",
    "    icdnames[tokens[1].replace('\"','')] = tokens[2]\n",
    "icd_dict_file.close()\n",
    "\n",
    "icd_scores = {}\n",
    "med_scores = {}\n",
    "lab_scores = {}\n",
    "\n",
    "icd_totals = {}\n",
    "med_totals = {}\n",
    "lab_totals = {}\n",
    "\n",
    "def get_ICD(icd):\n",
    "    '''\n",
    "    Given icd integer index, return the string name of that icd code:\n",
    "    e.g. get_ICD(1) returns \"Hypertension NOS\"\n",
    "    '''\n",
    "    ret_str = \"\"\n",
    "    icd_key_lst = list(icditems.keys())\n",
    "    icd_val_ind = list(icditems.values())[icd]\n",
    "    icd_str = icd_key_lst[icd_val_ind]\n",
    "    actual_key = icd_str.replace(\".\", \"\")[2:]\n",
    "    if actual_key in icdnames:\n",
    "        ret_str = icdnames[actual_key]\n",
    "    else:\n",
    "        ret_str = icd_str\n",
    "    return ret_str\n",
    "\n",
    "def get_med(med):\n",
    "    '''\n",
    "    Given icd integer index, return the string name of that med code:\n",
    "    e.g. get_med(1) returns \"Phenylephrine HCl\"\n",
    "    '''\n",
    "    med_key_lst = list(meditems.keys())\n",
    "    med_val_ind = list(meditems.values())[med]\n",
    "    ret_str = med_key_lst[med_val_ind]\n",
    "    return ret_str\n",
    "\n",
    "def get_lab(lab):\n",
    "    '''\n",
    "    Given lab integer index, return the string name of that lab code:\n",
    "    e.g. get_lab(1) returns \"Hemoglobin\"\n",
    "    '''\n",
    "    lab_key_lst = list(labitems.keys())\n",
    "    lab_val_ind = list(labitems.values())[lab]\n",
    "    ret_str = labnames[lab_key_lst[lab_val_ind]]\n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6e1a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(icd_seq, med_seq, lab_seq, model, actual_score, full_icd):\n",
    "    potential_test_data = []\n",
    "\n",
    "    for seq in range(len(icd_seq)):\n",
    "        for i in range(len(icd_seq[seq])):\n",
    "            potential_test_data.append((\"icd\", full_icd[seq][i], seq, icd_seq[:seq]+[icd_seq[seq][:i] + icd_seq[seq][i+1:]]+icd_seq[seq+1:], med_seq, lab_seq))\n",
    "    for seq in range(len(med_seq)):\n",
    "        for i in range(len(med_seq[seq])):\n",
    "            potential_test_data.append((\"med\", med_seq[seq][i], seq, icd_seq, med_seq[:seq]+[med_seq[seq][:i]+med_seq[seq][i+1:]]+med_seq[seq+1:], lab_seq))\n",
    "    for seq in range(len(lab_seq)):\n",
    "        for i in range(len(lab_seq[seq])):\n",
    "            potential_test_data.append((\"lab\", lab_seq[seq][i], seq, icd_seq, med_seq, lab_seq[:seq]+[lab_seq[seq][:i] + lab_seq[seq][i+1:]]+lab_seq[seq+1:]))\n",
    "\n",
    "    risk_scores = []\n",
    "\n",
    "    for pt in potential_test_data:\n",
    "        test_input_icd = Variable(torch.from_numpy(convert_to_one_hot(pt[3], vocabsize_icd)).float())\n",
    "        test_input_med = Variable(torch.from_numpy(convert_to_one_hot(pt[4], vocabsize_meds)).float())\n",
    "        test_input_lab = Variable(torch.from_numpy(convert_to_one_hot(pt[5], vocabsize_labs)).float())\n",
    "        factor_score = actual_score - model.predict(test_input_icd, test_input_med, test_input_lab)\n",
    "        factor = \"\"\n",
    "        if pt[0] == 'icd':\n",
    "            icd_tag = get_ICD(pt[1])\n",
    "            factor = \"ICD-\"+icd_tag\n",
    "            if icd_tag in icd_scores:\n",
    "                icd_scores[icd_tag] += factor_score\n",
    "                icd_totals[icd_tag] += 1\n",
    "            else:\n",
    "                icd_scores[icd_tag] = factor_score\n",
    "                icd_totals[icd_tag] = 1\n",
    "        elif pt[0] == 'med':\n",
    "            med_tag = get_med(pt[1])\n",
    "            factor = \"Med-\"+med_tag\n",
    "            if med_tag in med_scores:\n",
    "                med_scores[med_tag] += factor_score\n",
    "                med_totals[med_tag] += 1\n",
    "            else:\n",
    "                med_scores[med_tag] = factor_score\n",
    "                med_totals[med_tag] = 1\n",
    "        else:\n",
    "            lab_tag = get_lab(pt[1])\n",
    "            factor = \"Lab-\"+lab_tag\n",
    "            if lab_tag in lab_scores:\n",
    "                lab_scores[lab_tag] += factor_score\n",
    "                lab_totals[lab_tag] += 1\n",
    "            else:\n",
    "                lab_scores[lab_tag] = factor_score\n",
    "                lab_totals[lab_tag] = 1\n",
    "        risk_scores.append((\"Encounter-\"+str(pt[2])+\": \"+factor, factor_score))\n",
    "\n",
    "    risk_scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    return risk_scores[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print \"Final testing and interpretations\"\n",
    "\n",
    "interpretation_file = open(out_path + \"RNN_Concat_Interpretations.txt\", 'w')\n",
    "predictions = np.zeros(len(test_input_seqs_icd))\n",
    "for i in (range(len(test_input_seqs_icd))):\n",
    "    test_input_icd = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_icd[i], vocabsize_icd)).float())\n",
    "    test_input_med = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_meds[i], vocabsize_meds)).float())\n",
    "    test_input_lab = Variable(torch.from_numpy(convert_to_one_hot(test_input_seqs_labs[i], vocabsize_labs)).float())\n",
    "\n",
    "    test_score = model.predict(test_input_icd, test_input_med, test_input_lab)\n",
    "    predictions[i] = test_score\n",
    "    top_risk_factors = get_factors(test_input_seqs_icd[i], test_input_seqs_meds[i], test_input_seqs_labs[i], model, test_score, test_input_seqs_fullicd[i]) \n",
    "    if (test_score>0.5):\n",
    "        interpretation_file.write(\"ID: \" + str(i) + \" True label: \"+str(test_labels[i])+\"\\n\")\n",
    "        for rf in top_risk_factors:\n",
    "            interpretation_file.write(str(rf)+\"\\n\")\n",
    "        interpretation_file.write(\"\\n\")\n",
    "\n",
    "interpretation_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a85e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

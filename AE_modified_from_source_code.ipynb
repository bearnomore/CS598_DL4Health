{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bfe1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0faa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabsize_icd = 942 #only diagnoses 3 digit icd codes\n",
    "vocabsize_meds = 3202 #med codes\n",
    "vocabsize_labs = 284 #abnormal lab codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fcb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/MIMIC_Processed/'\n",
    "icd_seqs = pickle.load(open(os.path.join(DATA_PATH,'MIMICIIIPROCESSED.3digitICD9.seqs'), 'rb'))\n",
    "med_seqs = pickle.load(open(os.path.join(DATA_PATH,'MIMICIIIPROCESSED.meds.seqs'), 'rb'))\n",
    "lab_seqs = pickle.load(open(os.path.join(DATA_PATH,'MIMICIIIPROCESSED.abnlabs.seqs'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9c7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_encounter(seqs, vocab):\n",
    "    ret_vector = np.zeros([len(seqs), vocab])\n",
    "    for i, enc in enumerate(seqs):\n",
    "#         print(i)\n",
    "        for code in enc:\n",
    "            ret_vector[i, code] = 1\n",
    "    return ret_vector.sum(axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967b3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnoses icd9 feature\n",
    "input_icd = torch.tensor(np.array([combine_encounter(icd_seqs[i], vocabsize_icd) for i in range(0, len(icd_seqs))]))\n",
    "\n",
    "# med feature\n",
    "input_med = torch.tensor(np.array([combine_encounter(med_seqs[i], vocabsize_meds) for i in range(0, len(med_seqs))]))\n",
    "\n",
    "# abnormal lab feature\n",
    "input_lab = torch.tensor(np.array([combine_encounter(lab_seqs[i], vocabsize_labs) for i in range(0, len(lab_seqs))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1b12e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7537, 942])\n",
      "torch.Size([7537, 3202])\n",
      "torch.Size([7537, 284])\n"
     ]
    }
   ],
   "source": [
    "print(input_icd.shape)\n",
    "print(input_med.shape)\n",
    "print(input_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebca1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7537, 4428])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_full = torch.cat((input_icd, input_med, input_lab),1)\n",
    "input_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa1d741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, epochs, batchsize, embsize):\n",
    "        super(AE, self).__init__()\n",
    "        self.epochs = epochs\n",
    "        self.batchsize = batchsize\n",
    "        self.embsize = embsize\n",
    "\n",
    "        self.emb = nn.Linear(vocabsize_icd + vocabsize_meds + vocabsize_labs, self.embsize)\n",
    "\n",
    "        self.out = nn.Linear(self.embsize, vocabsize_icd + vocabsize_meds + vocabsize_labs)\n",
    "\n",
    "        self.reconloss = nn.MSELoss(size_average=True)\n",
    "\n",
    "    def forward(self, input_icd, input_med, input_lab):\n",
    "\n",
    "        input_full = torch.cat((input_icd, input_med, input_lab),1)\n",
    "\n",
    "        hidden_full = F.relu(self.emb(input_full))\n",
    "\n",
    "        output_full = F.relu(self.out(hidden_full))\n",
    "\n",
    "        return [output_full, hidden_full]\n",
    "\n",
    "    def get_encodings(self, ICD_data, Lab_data):\n",
    "        return self.forward(Variable(torch.from_numpy(ICD_data).float()), Variable(torch.from_numpy(Lab_data).float()))[-1]\n",
    "\n",
    "    def fit(self, ICDs, Meds, Labs):\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), 0.01)\n",
    "\n",
    "        prev_loss = 1000\n",
    "        for epoch in range(self.epochs):\n",
    "            print('Epoch:', epoch)\n",
    "\n",
    "            perm = np.random.permutation(ICDs.shape[0])\n",
    "            ICDs = ICDs[perm]\n",
    "            Meds = Meds[perm]\n",
    "            Labs = Labs[perm]\n",
    "\n",
    "            losses = []\n",
    "\n",
    "            for i in range(0, ICDs.shape[0], self.batchsize):\n",
    "                ICDbatch, Medbatch, Labbatch = ICDs[i:i+self.batchsize], Meds[i:i+self.batchsize], Labs[i:i+self.batchsize]\n",
    "                ICDbatchvar, Medbatchvar, Labbatchvar = Variable(ICDbatch.float()), \\\n",
    "                                                        Variable(Medbatch.float()), \\\n",
    "                                                        Variable(Labbatch.float())\n",
    "\n",
    "                outputs = self.forward(ICDbatchvar, Medbatchvar, Labbatchvar)\n",
    "\n",
    "                loss = self.reconloss(outputs[0], torch.cat((ICDbatchvar, Medbatchvar, Labbatchvar),1))\n",
    "\n",
    "                losses.append(loss.data)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                # print 'recon loss:', loss_recon.data[0], 'loss_cr:', loss_cr.data[0]\n",
    "\n",
    "            print('Epoch loss:', np.mean(losses))\n",
    "\n",
    "            if abs(np.mean(losses) - prev_loss) < 0.00005:\n",
    "                break\n",
    "\n",
    "            prev_loss = np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e479f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch loss: 0.047882527\n",
      "Epoch: 1\n",
      "Epoch loss: 0.0480279\n",
      "Epoch: 2\n",
      "Epoch loss: 0.04901274\n",
      "Epoch: 3\n",
      "Epoch loss: 0.046973605\n",
      "Epoch: 4\n",
      "Epoch loss: 0.047023993\n",
      "Epoch: 5\n",
      "Epoch loss: 0.04575749\n",
      "Epoch: 6\n",
      "Epoch loss: 0.04655977\n",
      "Epoch: 7\n",
      "Epoch loss: 0.046920467\n",
      "Epoch: 8\n",
      "Epoch loss: 0.04828365\n",
      "Epoch: 9\n",
      "Epoch loss: 0.048332077\n"
     ]
    }
   ],
   "source": [
    "model = AE(10,50,175)\n",
    "\n",
    "model.fit(input_icd,input_med, input_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b57a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled embedding weights. Shape: (4428, 175)\n"
     ]
    }
   ],
   "source": [
    "emb_weights = model._modules['emb'].weight.data.numpy().T\n",
    "print('Pickled embedding weights. Shape:', np.array(emb_weights).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90e7d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out_path = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/Output/'\n",
    "pickle.dump(emb_weights, open(Out_path + 'AE_embedding_weights.npy', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66962a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

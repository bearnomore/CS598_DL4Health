{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20eb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf19300",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/DataProcessed/'\n",
    "data_path = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/MIMIC data/'\n",
    "out_path = 'E:/CS_Master_Degree_UIUC/CS598_DeepLearning_for_Health_Data/Project/paper290/Output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2aadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vocabulary sizes were all updated per preprocessed results\n",
    "vocabsize_icd = 1071 #all 6985\n",
    "vocabsize_meds = 4525\n",
    "vocabsize_labs = 302 #all 710\n",
    "vocabsize = vocabsize_icd+vocabsize_meds+vocabsize_labs\n",
    "\n",
    "input_seqs_icd = np.array(pickle.load(open(input_path +'MIMICIIIPROCESSED.3digitICD9.seqs', 'rb')))\n",
    "input_seqs_meds = np.array(pickle.load(open(input_path +'MIMICIIIPROCESSED.meds.seqs', 'rb')))\n",
    "input_seqs_labs = np.array(pickle.load(open(input_path +'MIMICIIIPROCESSED.abnlabs.seqs', 'rb')))\n",
    "input_seqs_fullicd = np.array(pickle.load(open(input_path +'MIMICIIIPROCESSED.seqs', 'rb')))\n",
    "labels = np.array(pickle.load(open(input_path +'MIMICIIIPROCESSED.morts', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c0a3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = open(\"logistic_regression_interpretations.txt\", 'w')\n",
    "\n",
    "def combine_encounter(seqs, length):\n",
    "    ret_vector = np.zeros(length)\n",
    "    for i, enc in enumerate(seqs):\n",
    "#         print(i)\n",
    "        for code in enc:\n",
    "            ret_vector[code] = 1\n",
    "\n",
    "    return ret_vector\n",
    "\n",
    "# for modeling using only diagnoses icd9 feature\n",
    "input_icds = np.array([combine_encounter(input_seqs_icd[i], vocabsize_icd) for i in range(0, len(input_seqs_icd))])\n",
    "\n",
    "# for modeling using only med feature\n",
    "input_meds = np.array([combine_encounter(input_seqs_meds[i], vocabsize_meds) for i in range(0, len(input_seqs_meds))])\n",
    "\n",
    "# for modeling using only abnormal lab feature\n",
    "input_labs = np.array([combine_encounter(input_seqs_labs[i], vocabsize_labs) for i in range(0, len(input_seqs_labs))])\n",
    "\n",
    "# for modeling with concatenated features\n",
    "input_seqs = np.array([np.concatenate((combine_encounter(input_seqs_icd[i], vocabsize_icd), \n",
    "                                       combine_encounter(input_seqs_meds[i], vocabsize_meds), \n",
    "                                       combine_encounter(input_seqs_labs[i], vocabsize_labs)), axis=0) for i in range(0, len(input_seqs_icd))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4d88794",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainratio = 0.7\n",
    "validratio = 0.1\n",
    "testratio = 0.2\n",
    "\n",
    "trainlindex = int(len(input_seqs_icd)*trainratio)\n",
    "validlindex = int(len(input_seqs_icd)*(trainratio + validratio))\n",
    "\n",
    "labnames = {}\n",
    "lab_dict_file = open(data_path + 'D_LABITEMS.csv', 'r')\n",
    "lab_dict_file.readline()\n",
    "for line in lab_dict_file:\n",
    "    tokens = line.strip().split(',')\n",
    "    labnames[tokens[1].replace('\"','')] = tokens[2]\n",
    "lab_dict_file.close()\n",
    "\n",
    "icdnames = {}\n",
    "icd_dict_file = open(data_path + 'D_ICD_DIAGNOSES.csv', 'r')\n",
    "icd_dict_file.readline()\n",
    "for line in icd_dict_file:\n",
    "    tokens = line.strip().split(',')\n",
    "    icdnames[tokens[1].replace('\"','')] = tokens[2]\n",
    "icd_dict_file.close()\n",
    "\n",
    "icditems = pickle.load(open(input_path + 'MIMICIIIPROCESSED.types', 'rb'))\n",
    "meditems = pickle.load(open(input_path + 'MIMICIIIPROCESSED.meds.types', 'rb'))\n",
    "labitems = pickle.load(open(input_path + 'MIMICIIIPROCESSED.abnlabs.types', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f846df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ICD(icd):\n",
    "    ret_str = \"\"\n",
    "    icd_key_lst = list(icditems.keys())\n",
    "    icd_val_ind = list(icditems.values())[icd]\n",
    "    icd_str = icd_key_lst[icd_val_ind]\n",
    "    actual_key = icd_str.replace(\".\", \"\")[2:]\n",
    "    if actual_key in icdnames:\n",
    "        ret_str = icdnames[actual_key]\n",
    "    else:\n",
    "        ret_str = icd_str\n",
    "    return ret_str\n",
    "\n",
    "def get_med(med):\n",
    "    med_key_lst = list(meditems.keys())\n",
    "    med_val_ind = list(meditems.values())[med]\n",
    "    ret_str = med_key_lst[med_val_ind]\n",
    "    return ret_str\n",
    "\n",
    "def get_lab(lab):\n",
    "    lab_key_lst = list(labitems.keys())\n",
    "    lab_val_ind = list(labitems.values())[lab]\n",
    "    ret_str = labnames[lab_key_lst[lab_val_ind]]\n",
    "    return ret_str\n",
    "\n",
    "def get_factor(i, patid):\n",
    "    if i<1071:\n",
    "        return get_ICD(pattofullicd_dict[patid][i]), 0\n",
    "    elif i<1071+4525:\n",
    "        return get_med(i-1071), 1\n",
    "    else:\n",
    "        return get_lab(i-4525-1071), 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad7aaf",
   "metadata": {},
   "source": [
    "### Modeling with only diagnoses ICD codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec8fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Validation AUC_ROC:  0.8625110248598417\n",
      "Test AUC_ROC:  0.8745527599170151\n",
      "Run 1\n",
      "Validation AUC_ROC:  0.872348434149606\n",
      "Test AUC_ROC:  0.8705578450164293\n",
      "Run 2\n",
      "Validation AUC_ROC:  0.8580634580665418\n",
      "Test AUC_ROC:  0.8685471317086528\n",
      "Run 3\n",
      "Validation AUC_ROC:  0.8700937540855376\n",
      "Test AUC_ROC:  0.8712719688703326\n",
      "Run 4\n",
      "Validation AUC_ROC:  0.8725046550163139\n",
      "Test AUC_ROC:  0.8714452298717611\n",
      "Run 5\n",
      "Validation AUC_ROC:  0.8664110867339795\n",
      "Test AUC_ROC:  0.8692525675805549\n",
      "Run 6\n",
      "Validation AUC_ROC:  0.868168445374463\n",
      "Test AUC_ROC:  0.8669152057997642\n",
      "Run 7\n",
      "Validation AUC_ROC:  0.8642507380481348\n",
      "Test AUC_ROC:  0.8743292370796094\n",
      "Run 8\n",
      "Validation AUC_ROC:  0.8719781562946063\n",
      "Test AUC_ROC:  0.8782778668075079\n",
      "Run 9\n",
      "Validation AUC_ROC:  0.8665964687124305\n",
      "Test AUC_ROC:  0.8665874702201887\n",
      "Average AUCROC: 0.8711737282871816 +/- 0.0034937829929205665\n"
     ]
    }
   ],
   "source": [
    "best_aucrocs = []\n",
    "for run in range(10):\n",
    "    print('Run', run)\n",
    "\n",
    "    perm = np.random.permutation(input_icds.shape[0])\n",
    "    rinput_seqs = input_icds[perm]\n",
    "    rlabels = labels[perm]\n",
    "\n",
    "    train_input_seqs = rinput_seqs[:trainlindex]\n",
    "    train_labels = rlabels[:trainlindex]\n",
    "\n",
    "    valid_input_seqs = rinput_seqs[trainlindex:validlindex]\n",
    "    valid_labels = rlabels[trainlindex:validlindex]\n",
    "\n",
    "    test_input_seqs = rinput_seqs[validlindex:]\n",
    "    test_labels = rlabels[validlindex:]\n",
    "    test_input_seqs_interpretations = rinput_seqs[validlindex:]\n",
    "\n",
    "    model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "    model.fit(train_input_seqs, train_labels)\n",
    "\n",
    "    vpredict_probabilities = np.array([a[1] for a in model.predict_proba(valid_input_seqs)])\n",
    "    print(\"Validation AUC_ROC: \", roc_auc_score(valid_labels, vpredict_probabilities))\n",
    "\n",
    "    predict_probabilities = np.array([a[1] for a in model.predict_proba(test_input_seqs)])\n",
    "    print(\"Test AUC_ROC: \", roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "    best_aucrocs.append(roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "print(\"Average AUCROC:\", np.mean(best_aucrocs), \"+/-\", np.std(best_aucrocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c31b8",
   "metadata": {},
   "source": [
    "### Modeling with on medication feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b913fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Validation AUC_ROC:  0.8289482845161186\n",
      "Test AUC_ROC:  0.8381359144510755\n",
      "Run 1\n",
      "Validation AUC_ROC:  0.8174112732933784\n",
      "Test AUC_ROC:  0.8436212129308622\n",
      "Run 2\n",
      "Validation AUC_ROC:  0.8437161567436261\n",
      "Test AUC_ROC:  0.83297411034039\n",
      "Run 3\n",
      "Validation AUC_ROC:  0.8349390228117031\n",
      "Test AUC_ROC:  0.8380151715646871\n",
      "Run 4\n",
      "Validation AUC_ROC:  0.8390939828241775\n",
      "Test AUC_ROC:  0.8374440605970046\n",
      "Run 5\n",
      "Validation AUC_ROC:  0.8504438369814038\n",
      "Test AUC_ROC:  0.838266647272158\n",
      "Run 6\n",
      "Validation AUC_ROC:  0.829046602096121\n",
      "Test AUC_ROC:  0.843218401505365\n",
      "Run 7\n",
      "Validation AUC_ROC:  0.8444933583791762\n",
      "Test AUC_ROC:  0.8398961912905492\n",
      "Run 8\n",
      "Validation AUC_ROC:  0.8382423123799126\n",
      "Test AUC_ROC:  0.8382886592013117\n",
      "Run 9\n",
      "Validation AUC_ROC:  0.8327802764749581\n",
      "Test AUC_ROC:  0.839106497030648\n",
      "Average AUCROC: 0.8388966866184051 +/- 0.0028522082771989476\n"
     ]
    }
   ],
   "source": [
    "best_aucrocs = []\n",
    "for run in range(10):\n",
    "    print('Run', run)\n",
    "\n",
    "    perm = np.random.permutation(input_meds.shape[0])\n",
    "    rinput_seqs = input_meds[perm]\n",
    "    rlabels = labels[perm]\n",
    "\n",
    "    train_input_seqs = rinput_seqs[:trainlindex]\n",
    "    train_labels = rlabels[:trainlindex]\n",
    "\n",
    "    valid_input_seqs = rinput_seqs[trainlindex:validlindex]\n",
    "    valid_labels = rlabels[trainlindex:validlindex]\n",
    "\n",
    "    test_input_seqs = rinput_seqs[validlindex:]\n",
    "    test_labels = rlabels[validlindex:]\n",
    "    test_input_seqs_interpretations = rinput_seqs[validlindex:]\n",
    "\n",
    "    model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "    model.fit(train_input_seqs, train_labels)\n",
    "\n",
    "    vpredict_probabilities = np.array([a[1] for a in model.predict_proba(valid_input_seqs)])\n",
    "    print(\"Validation AUC_ROC: \", roc_auc_score(valid_labels, vpredict_probabilities))\n",
    "\n",
    "    predict_probabilities = np.array([a[1] for a in model.predict_proba(test_input_seqs)])\n",
    "    print(\"Test AUC_ROC: \", roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "    best_aucrocs.append(roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "print(\"Average AUCROC:\", np.mean(best_aucrocs), \"+/-\", np.std(best_aucrocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d0aeb",
   "metadata": {},
   "source": [
    "### Modeling with only lab feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adec8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Validation AUC_ROC:  0.816334671410292\n",
      "Test AUC_ROC:  0.8180436563438287\n",
      "Run 1\n",
      "Validation AUC_ROC:  0.8148430081547692\n",
      "Test AUC_ROC:  0.8134909943369953\n",
      "Run 2\n",
      "Validation AUC_ROC:  0.8101621466234638\n",
      "Test AUC_ROC:  0.815339305792318\n",
      "Run 3\n",
      "Validation AUC_ROC:  0.8219084873679714\n",
      "Test AUC_ROC:  0.815064318232513\n",
      "Run 4\n",
      "Validation AUC_ROC:  0.8275171521127935\n",
      "Test AUC_ROC:  0.8237439294925875\n",
      "Run 5\n",
      "Validation AUC_ROC:  0.8297562726216542\n",
      "Test AUC_ROC:  0.821424266118638\n",
      "Run 6\n",
      "Validation AUC_ROC:  0.8235573693961252\n",
      "Test AUC_ROC:  0.8193252633704455\n",
      "Run 7\n",
      "Validation AUC_ROC:  0.8121092845888931\n",
      "Test AUC_ROC:  0.8100109444926219\n",
      "Run 8\n",
      "Validation AUC_ROC:  0.8018404259342211\n",
      "Test AUC_ROC:  0.8211440359050048\n",
      "Run 9\n",
      "Validation AUC_ROC:  0.8192805150949648\n",
      "Test AUC_ROC:  0.8111088879996443\n",
      "Average AUCROC: 0.8168695602084597 +/- 0.004369481199989567\n"
     ]
    }
   ],
   "source": [
    "best_aucrocs = []\n",
    "for run in range(10):\n",
    "    print('Run', run)\n",
    "\n",
    "    perm = np.random.permutation(input_labs.shape[0])\n",
    "    rinput_seqs = input_labs[perm]\n",
    "    rlabels = labels[perm]\n",
    "\n",
    "    train_input_seqs = rinput_seqs[:trainlindex]\n",
    "    train_labels = rlabels[:trainlindex]\n",
    "\n",
    "    valid_input_seqs = rinput_seqs[trainlindex:validlindex]\n",
    "    valid_labels = rlabels[trainlindex:validlindex]\n",
    "\n",
    "    test_input_seqs = rinput_seqs[validlindex:]\n",
    "    test_labels = rlabels[validlindex:]\n",
    "    test_input_seqs_interpretations = rinput_seqs[validlindex:]\n",
    "\n",
    "    model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "    model.fit(train_input_seqs, train_labels)\n",
    "\n",
    "    vpredict_probabilities = np.array([a[1] for a in model.predict_proba(valid_input_seqs)])\n",
    "    print(\"Validation AUC_ROC: \", roc_auc_score(valid_labels, vpredict_probabilities))\n",
    "\n",
    "    predict_probabilities = np.array([a[1] for a in model.predict_proba(test_input_seqs)])\n",
    "    print(\"Test AUC_ROC: \", roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "    best_aucrocs.append(roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "print(\"Average AUCROC:\", np.mean(best_aucrocs), \"+/-\", np.std(best_aucrocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf836c5",
   "metadata": {},
   "source": [
    "### Modeling with concatenated features (diagnoses icds +  medications + abnormal lab components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a40359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Validation AUC_ROC:  0.9035571922286929\n",
      "Test AUC_ROC:  0.9081647220437435\n",
      "Run 1\n",
      "Validation AUC_ROC:  0.9018085605521937\n",
      "Test AUC_ROC:  0.9022555420627703\n",
      "Run 2\n",
      "Validation AUC_ROC:  0.9062489733377497\n",
      "Test AUC_ROC:  0.901601217462055\n",
      "Run 3\n",
      "Validation AUC_ROC:  0.8966805367619923\n",
      "Test AUC_ROC:  0.901580479230438\n",
      "Run 4\n",
      "Validation AUC_ROC:  0.8997072145482338\n",
      "Test AUC_ROC:  0.8935310175911682\n",
      "Run 5\n",
      "Validation AUC_ROC:  0.9003184303072719\n",
      "Test AUC_ROC:  0.8976782830671866\n",
      "Run 6\n",
      "Validation AUC_ROC:  0.9082330140405183\n",
      "Test AUC_ROC:  0.9000080175174793\n",
      "Run 7\n",
      "Validation AUC_ROC:  0.9020573177255856\n",
      "Test AUC_ROC:  0.9011704346355244\n",
      "Run 8\n",
      "Validation AUC_ROC:  0.900692498566354\n",
      "Test AUC_ROC:  0.9027827575514267\n",
      "Run 9\n",
      "Validation AUC_ROC:  0.8963414499828181\n",
      "Test AUC_ROC:  0.9008529323044622\n",
      "Average AUCROC: 0.9009625403466254 +/- 0.0035302471069723084\n"
     ]
    }
   ],
   "source": [
    "best_aucrocs = []\n",
    "for run in range(10):\n",
    "    print('Run', run)\n",
    "\n",
    "    perm = np.random.permutation(input_seqs.shape[0])\n",
    "    rinput_seqs = input_seqs[perm]\n",
    "    rinput_seqs_fullicd = input_seqs_fullicd[perm]\n",
    "    rlabels = labels[perm]\n",
    "    r_input_icd = input_seqs_icd[perm]\n",
    "\n",
    "    train_input_seqs = rinput_seqs[:trainlindex]\n",
    "    train_input_seqs_fullicd = rinput_seqs_fullicd[:trainlindex]\n",
    "    train_labels = rlabels[:trainlindex]\n",
    "\n",
    "    valid_input_seqs = rinput_seqs[trainlindex:validlindex]\n",
    "    valid_input_seqs_fullicd = rinput_seqs_fullicd[trainlindex: validlindex]\n",
    "    valid_labels = rlabels[trainlindex:validlindex]\n",
    "\n",
    "    test_input_seqs = rinput_seqs[validlindex:]\n",
    "    test_input_seqs_fullicd = rinput_seqs_fullicd[validlindex:]\n",
    "    test_labels = rlabels[validlindex:]\n",
    "    test_input_seqs_interpretations = r_input_icd[validlindex:]\n",
    "\n",
    "    model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "    model.fit(train_input_seqs, train_labels)\n",
    "\n",
    "    vpredict_probabilities = np.array([a[1] for a in model.predict_proba(valid_input_seqs)])\n",
    "    print(\"Validation AUC_ROC: \", roc_auc_score(valid_labels, vpredict_probabilities))\n",
    "\n",
    "    predict_probabilities = np.array([a[1] for a in model.predict_proba(test_input_seqs)])\n",
    "    print(\"Test AUC_ROC: \", roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "    best_aucrocs.append(roc_auc_score(test_labels, predict_probabilities))\n",
    "\n",
    "print(\"Average AUCROC:\", np.mean(best_aucrocs), \"+/-\", np.std(best_aucrocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e39bb1",
   "metadata": {},
   "source": [
    "### Find the top 10 risk ICD factors for patient having predicted death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f135b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_file = open(out_path + \"Log_Reg_Interpretations.txt\", 'w')\n",
    "\n",
    "pattofullicd_dict = {}\n",
    "for i in range(len(test_input_seqs_interpretations)):\n",
    "    icdtofullicd_dict = {}\n",
    "    for j in range(len(test_input_seqs_interpretations[i])):\n",
    "        for k in range(len(test_input_seqs_interpretations[i][j])):\n",
    "            icdtofullicd_dict[test_input_seqs_interpretations[i][j][k]] = test_input_seqs_fullicd[i][j][k]\n",
    "    pattofullicd_dict[i] = icdtofullicd_dict\n",
    "\n",
    "coeffs = np.array(model.coef_[0])\n",
    "for patid in range(len(test_input_seqs)):\n",
    "    test_input = test_input_seqs[patid]\n",
    "\n",
    "    scores = (test_input*coeffs)\n",
    "    # scores = coeffs\n",
    "    risk_scores = []\n",
    "    for i in range(len(scores)):\n",
    "        if test_input[i]>0:\n",
    "            factors = get_factor(i, patid)\n",
    "            risk_scores.append((factors[0], scores[i]))\n",
    "    risk_scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    top_risk_factors = risk_scores[:10]\n",
    "\n",
    "    if (predict_probabilities[patid] > 0.5):\n",
    "        interpretation_file.write(\"ID: \" + str(patid) + \" True label: \"+str(test_labels[patid])+\"\\n\")\n",
    "        for rf in top_risk_factors:\n",
    "            interpretation_file.write(str(rf)+\"\\n\")\n",
    "        interpretation_file.write(\"\\n\")\n",
    "\n",
    "interpretation_file.close()\n",
    "\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(test_labels, predict_probabilities)\n",
    "# pickle.dump({\"FPR\":fpr, \"TPR\":tpr}, open('roc_lr.p', 'wb'))\n",
    "# actual_predictions = (predict_probabilities>0.5)*1\n",
    "\n",
    "# print classification_report(test_labels, actual_predictions)\n",
    "# coeffs = np.array(model.coef_[0])\n",
    "\n",
    "# icd_scores = {}\n",
    "# icd_totals = {}\n",
    "# med_scores = {}\n",
    "# med_totals = {}\n",
    "# lab_scores = {}\n",
    "# lab_totals = {}\n",
    "\n",
    "# for patid in range(len(test_input_seqs)):\n",
    "# \ttest_input = test_input_seqs[patid]\n",
    "# \tscores = (test_input*coeffs)\n",
    "# \t# scores = coeffs\n",
    "# \tfor i in range(len(scores)):\n",
    "# \t\tif test_input[i]>0:\n",
    "# \t\t\tfactors = get_factor(i, patid)\n",
    "# \t\t\tif factors[1] == 0:\n",
    "# \t\t\t\tif factors[0] in icd_scores:\n",
    "# \t\t\t\t\ticd_scores[factors[0]] += scores[i]\n",
    "# \t\t\t\t\ticd_totals[factors[0]] += 1\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\ticd_scores[factors[0]] = scores[i]\n",
    "# \t\t\t\t\ticd_totals[factors[0]] = 1\n",
    "# \t\t\telif factors[1] == 1:\n",
    "# \t\t\t\tif factors[0] in med_scores:\n",
    "# \t\t\t\t\tmed_scores[factors[0]] += scores[i]\n",
    "# \t\t\t\t\tmed_totals[factors[0]] += 1\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\tmed_scores[factors[0]] = scores[i]\n",
    "# \t\t\t\t\tmed_totals[factors[0]] = 1\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tif factors[0] in lab_scores:\n",
    "# \t\t\t\t\tlab_scores[factors[0]] += scores[i]\n",
    "# \t\t\t\t\tlab_totals[factors[0]] += 1\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\tlab_scores[factors[0]] = scores[i]\n",
    "# \t\t\t\t\tlab_totals[factors[0]] = 1\n",
    "\n",
    "\n",
    "# icd_averages = []\n",
    "# med_averages = []\n",
    "# lab_averages = []\n",
    "\n",
    "# for factor in icd_scores:\n",
    "# \ticd_averages.append((factor, icd_scores[factor]/icd_totals[factor]))\n",
    "# icd_averages.sort(key=lambda tup: tup[1], reverse=True)\n",
    "# fout.write(\"ICD codes:\\n\")\n",
    "# for item in icd_averages:\n",
    "# \tfout.write(item[0]+\"-\"+str(item[1])+\"\\n\")\n",
    "# fout.write(\"\\n\")\n",
    "\n",
    "# for factor in med_scores:\n",
    "# \tmed_averages.append((factor, med_scores[factor]/med_totals[factor]))\n",
    "# med_averages.sort(key=lambda tup: tup[1], reverse=True)\n",
    "# fout.write(\"Medications:\\n\")\n",
    "# for item in med_averages:\n",
    "# \tfout.write(item[0]+\"-\"+str(item[1])+\"\\n\")\n",
    "# fout.write(\"\\n\")\n",
    "\n",
    "# for factor in lab_scores:\n",
    "# \tlab_averages.append((factor, lab_scores[factor]/lab_totals[factor]))\n",
    "# lab_averages.sort(key=lambda tup: tup[1], reverse=True)\n",
    "# fout.write(\"Lab components:\\n\")\n",
    "# for item in lab_averages:\n",
    "# \tfout.write(item[0]+\"-\"+str(item[1])+\"\\n\")\n",
    "# fout.write(\"\\n\")\n",
    "\n",
    "# scores = [(scores[i], get_factor(i)) for i in range(len(scores)) if test_input[i]>0]\n",
    "# scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "# for factor in scores:\n",
    "# \tif factor[1] in [\"\\\"Encephalopathy NOS\\\"\", \"\\\"Bleed esoph var oth dis\\\"\", \"\\\"Lactulose Enema\\\"\", \"\\\"Cirrhosis of liver NOS\\\"\", \"\\\"Urin tract infection NOS\\\"\", \"\\\"Phytonadione\\\"\", \"\\\"Hy kid NOS w cr kid I-IV\\\"\", \"\\\"Mal neo liver\", \"\\\"Red blood cells\\\"\", \"\\\"RDW\\\"\", \"\\\"Hemoglobin\\\"\", \"\\\"0.9% Sodium Chloride\\\"\"]:\n",
    "# \t\tprint factor\n",
    "\n",
    "#for factor in scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c72671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
